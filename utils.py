# -*- coding: utf-8 -*-
"""Extracting_data_from_image_pdfs_MS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11VWHkYqIQXd-SlxDndRngg0L-bnumJjw
"""

# !pip install PyPDF2
# !pip install pytesseract
# !pip install pdf2image
# !apt-get install poppler-utils

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import make_interp_spline, CubicSpline
import re
from PyPDF2 import PdfReader
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
import string
import json
import os
import PyPDF2
import pytesseract
import pytesseract
from pdf2image import convert_from_path
from PyPDF2 import PdfReader
import multiprocessing

keywords = {"stress", "strain", "additive manufacturing", "cast", "forge", "powder", "rolling", "extrusion"}
# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

# Function to extract text from a text-based PDF
def extract_text_from_text_based_pdf(pdf_file_path):
    text = ""
    try:
        with open(pdf_file_path, 'rb') as file:
            reader = PdfReader(file)
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text
    except Exception as e:
        print(f"Error extracting text from PDF: {e}")
    return text

# Function to process a single image using Tesseract OCR
def ocr_image(image):
    return pytesseract.image_to_string(image)

# Optimized function using multiprocessing for image-based PDF OCR
def extract_text_from_image_based_pdf(pdf_file_path, dpi=200):
    images = convert_from_path(pdf_file_path, dpi=dpi)
    with multiprocessing.Pool() as pool:
        texts = pool.map(ocr_image, images)
    return ''.join(texts)

# Main function to handle both text-based and image-based PDFs
def extract_text_from_pdf(pdf_file_path):
    # First, attempt to extract text directly from a text-based PDF
    text = extract_text_from_text_based_pdf(pdf_file_path)

    # If no text was extracted, it's likely an image-based PDF, so use OCR
    if not text.strip():
        print("No text found, attempting OCR on image-based PDF...")
        text = extract_text_from_image_based_pdf(pdf_file_path)

    return text

import PyPDF2
import pytesseract
from pdf2image import convert_from_path
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
import string

# Ensure that you have Tesseract installed and provide its path if needed
# pytesseract.pytesseract.tesseract_cmd = r'path_to_tesseract_executable'

def extract_and_find_lemmas(text, keywords):
    all_lemmas = []

    # Tokenize the text
    words = word_tokenize(text)

    # Remove stop words and punctuation, and lemmatize
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()

    for word in words:
        if word.lower() not in stop_words and word not in string.punctuation:
            lemma = lemmatizer.lemmatize(word, pos=get_wordnet_pos(word))
            for keyword in keywords:
                if keyword in lemma and lemma not in all_lemmas:
                    all_lemmas.append(lemma)

    return text,all_lemmas


# Function to map POS tag to first character lemmatize() accepts
def get_wordnet_pos(word):
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ, "N": wordnet.NOUN, "V": wordnet.VERB, "R": wordnet.ADV}
    return tag_dict.get(tag, wordnet.NOUN)

import re
from PyPDF2 import PdfReader
import pytesseract
from pdf2image import convert_from_path

# Function to extract chemical compositions from a PDF file
def extract_chemical_compositions_from_pdf(text, min_length=8):
    combined_text = combine_words(text)  # Combine words to fix any split chemical formulas
    return extract_chemical_compositions(combined_text, min_length)

# Function to extract text from PDF (handles both text-based and image-based PDFs)
def extract_text_from_pdf(pdf_file_path):
    text = ""
    try:
        with open(pdf_file_path, "rb") as f:
            reader = PdfReader(f)
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text

        # If no text was extracted (likely image-based PDF), use OCR
        if not text.strip():
            print("No text extracted. Attempting OCR on image-based PDF...")
            text = extract_text_from_images(pdf_file_path)

    except Exception as e:
        print(f"Error reading PDF file: {e}")
    return text

# OCR function for image-based PDFs
def extract_text_from_images(pdf_file_path):
    images = convert_from_path(pdf_file_path)
    text = ""
    for image in images:
        text += pytesseract.image_to_string(image)
    return text

# Function to extract chemical compositions from a text
def extract_chemical_compositions(text, min_length=8):
    valid_elements = [
        "H", "He", "Li", "Be", "B", "C", "N", "O", "F", "Ne", "Na", "Mg", "Al", "Si", "P", "S", "Cl", "Ar",
        "K", "Ca", "Sc", "Ti", "V", "Cr", "Mn", "Fe", "Co", "Ni", "Cu", "Zn", "Ga", "Ge", "As", "Se", "Br",
        "Kr", "Rb", "Sr", "Y", "Zr", "Nb", "Mo", "Tc", "Ru", "Rh", "Pd", "Ag", "Cd", "In", "Sn", "Sb", "Te",
        "I", "Xe", "Cs", "Ba", "La", "Ce", "Pr", "Nd", "Pm", "Sm", "Eu", "Gd", "Tb", "Dy", "Ho", "Er", "Tm",
        "Yb", "Lu", "Hf", "Ta", "W", "Re", "Os", "Ir", "Pt", "Au", "Hg", "Tl", "Pb", "Bi", "Po", "At", "Rn",
        "Fr", "Ra", "Ac", "Th", "Pa", "U", "Np", "Pu", "Am", "Cm", "Bk", "Cf", "Es", "Fm", "Md", "No", "Lr",
        "Rf", "Db", "Sg", "Bh", "Hs", "Mt", "Ds", "Rg", "Cn", "Nh", "Fl", "Mc", "Lv", "Ts", "Og"
    ]
    # regular expression to check for the element
    # pattern = r'\b(?:[A-Z][a-z]?\d*(?:\.\d+)?)+\b'
    pattern = r'\b(?:[A-Z][a-z]?\d{0,2}(?:\.\d{1,2})?)+\b'
    chemical_compositions = re.findall(pattern, text)
    def is_valid_chemical(comp):
        parts = re.findall(r'[A-Z][a-z]?', comp)
        return all(element in valid_elements for element in parts)

    chemical_compositions = [comp for comp in chemical_compositions if len(comp) >= min_length and is_valid_chemical(comp)]
    return chemical_compositions

# Function to handle split chemical formulas (words that were separated in the text)
def combine_words(text):
    words = text.split()
    i = 0
    while i < len(words) - 1:
        if (words[i][-1].isdigit() and words[i+1][0].isalpha()) or (words[i][-1].isalpha() and words[i+1][0].isdigit()):
            words[i] += words[i+1]
            del words[i+1]
        else:
            i += 1
    return ' '.join(words)

# Function to create a dictionary of elements and their quantities from a chemical formula
def create_element_dictionary(chemical_composition):
    elements = {}
    matches = re.findall(r'([A-Z][a-z]?)(\d*\.?\d*)', chemical_composition)
    for match in matches:
        element = match[0]
        value = float(match[1]) if match[1] else 1.0
        elements[element] = value
    return elements

# def create_element_dictionary(chemical_composition):
#     matches = re.findall(r'([A-Z][a-z]?)(\d*\.?\d*)', chemical_composition)

#     # Initialize elements
#     elements = {}
#     for element, value in matches:
#         elements[element] = float(value) if value else None

#     given_values = [v for v in elements.values() if v is not None]
#     missing_elements = [k for k, v in elements.items() if v is None]

#     if not given_values:
#         # No numbers at all â†’ divide equally
#         num_elements = len(elements)
#         elements = {e: 100.0 / num_elements for e in elements}
#     else:
#         total_given = sum(given_values)

#         if total_given > 1:
#             # Assume % scale
#             remaining = 100.0 - total_given
#             share = remaining / len(missing_elements) if missing_elements else 0
#             for element in missing_elements:
#                 elements[element] = share
#         else:
#             # Assume fraction scale
#             remaining = 1.0 - total_given
#             share = remaining / len(missing_elements) if missing_elements else 0
#             for element in missing_elements:
#                 elements[element] = share
#             # After filling missing elements, normalize to 100
#             total_now = sum(elements.values())
#             elements = {e: (v * 100.0 / total_now) for e, v in elements.items()}

#     # Optional: round to 2 decimals for clean output
#     elements = {e: round(v, 2) for e, v in elements.items()}

#     return elements


# Main function to find the chemical composition with the maximum size and create a dictionary
def find_max_size_chemical(text):
    chemicals = extract_chemical_compositions_from_pdf(text)  # Extract chemicals
    combined_text = combine_words(text)  # Combine split words to ensure full chemical formulas
    chemicals = extract_chemical_compositions(combined_text)  # Re-extract after word combination

    print("Extracted chemical compositions:")
    print(chemicals)

    if not chemicals:
        print("No chemical compositions found in the text.")
        return None

    max_size_chemical = max(chemicals, key=len)  # Find the maximum length chemical formula
    print("\nMaximum sized chemical composition:", max_size_chemical)

    element_dict = create_element_dictionary(max_size_chemical)  # Creates a dictionary from the chemical formula
    return element_dict